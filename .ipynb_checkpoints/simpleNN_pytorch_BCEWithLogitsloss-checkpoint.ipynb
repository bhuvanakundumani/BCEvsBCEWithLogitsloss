{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 15)\n",
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat  medv  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "# setting the path for Data from data/housing folder\n",
    "DATA_FILE_TRAIN = './data/Boston.csv'\n",
    "#setting the random seed \n",
    "np.random.seed(42)\n",
    "# Loading the dataset\n",
    "train_data = pd.read_csv(DATA_FILE_TRAIN)\n",
    "print(train_data.shape)\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_1 = 101\n",
    "BATCH_SIZE_2 = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# To decide on the bin values\n",
    "print(train_data['medv'].max())\n",
    "print(train_data['medv'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
      "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
      "2   3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
      "3   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
      "4   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
      "\n",
      "   ptratio   black  lstat medv  \n",
      "0     15.3  396.90   4.98    0  \n",
      "1     17.8  396.90   9.14    0  \n",
      "2     17.8  392.83   4.03    1  \n",
      "3     18.7  394.63   2.94    1  \n",
      "4     18.7  396.90   5.33    1  \n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = [0,30,50]\n",
    "labels = [0,1]\n",
    "train_data['medv'] = pd.cut(train_data['medv'], bins=bins, labels=labels)\n",
    "print(train_data.head())\n",
    "print(len(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target class ratio is Counter({0: 422, 1: 84})\n"
     ]
    }
   ],
   "source": [
    "print(f\"The target class ratio is {Counter(train_data['medv']) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = ['ID']\n",
    "categorical_features = ['chas'] \n",
    "target_feature = 'medv'\n",
    "\n",
    "dropped_cols = id_col+categorical_features\n",
    "train_data = train_data.drop(dropped_cols, axis=1)\n",
    "all_features = train_data.columns.tolist()  #this will not have 'chas' and 'ID'\n",
    "\n",
    "numerical_features = list(set(all_features)- set([target_feature]))\n",
    "#print(len(numerical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "train_data_inp = train_data[numerical_features]\n",
    "train_data_tar = train_data[target_feature]\n",
    "Trn_input,  Val_inp, Trn_target,Val_target = train_test_split(train_data_inp, train_data_tar, test_size=0.2,random_state=123)\n",
    "# Train_data has our training dataset and Valid_data has our validation dataset.\n",
    "Train_data = pd.concat([Trn_input, pd.DataFrame(Trn_target)], axis=1)\n",
    "Valid_data = pd.concat([Val_inp, pd.DataFrame(Val_target)], axis=1)\n",
    "print(Train_data.shape)\n",
    "print(Valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oversampdata(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.FloatTensor(data.values.astype('float'))\n",
    "        print(self.data.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[index][-1]\n",
    "        data_val = self.data[index] [:-1]\n",
    "        return data_val,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([404, 13])\n",
      "torch.Size([102, 13])\n"
     ]
    }
   ],
   "source": [
    "# training and validation dataset \n",
    "train_dataset = oversampdata(Train_data)\n",
    "valid_dataset = oversampdata(Valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_1, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural network \n",
    "\n",
    "input_size = 12\n",
    "hidden_size = 128\n",
    "num_classes = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "                    \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    loss_total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in train_loader:\n",
    "        \n",
    "        #LOADING THE DATA IN A BATCH\n",
    "        data, target = i\n",
    " \n",
    "        # moving the tensors to the configured device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "       \n",
    "        #FORWARD PASS\n",
    "        target = target.float()\n",
    "        output = model(data.float())\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "        \n",
    "        loss_total += loss\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #PREDICTIONS BCELogitsloss()\n",
    "        pred = np.round(torch.sigmoid(output.detach()))\n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "\n",
    "    print(\"Accuracy on training set is\" , accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            data,target = i\n",
    "            \n",
    "            # moving the tensors to the configured device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            \n",
    "            output = model(data.float())\n",
    "            \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(torch.sigmoid(output))\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "            \n",
    "            \n",
    "    print(\"Accuracy on test set is\" , accuracy_score(y_true,y_pred))\n",
    "    print(\"********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimize\n",
    "model = LinearModel(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set is 0.4183168316831683\n",
      "Accuracy on test set is 0.6764705882352942\n",
      "********************************************************\n",
      "Accuracy on training set is 0.7673267326732673\n",
      "Accuracy on test set is 0.7843137254901961\n",
      "********************************************************\n",
      "Accuracy on training set is 0.844059405940594\n",
      "Accuracy on test set is 0.7941176470588235\n",
      "********************************************************\n",
      "Accuracy on training set is 0.844059405940594\n",
      "Accuracy on test set is 0.7941176470588235\n",
      "********************************************************\n",
      "Accuracy on training set is 0.844059405940594\n",
      "Accuracy on test set is 0.7941176470588235\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model_BCEWithLogitsloss.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
